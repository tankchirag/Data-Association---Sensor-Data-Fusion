{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from hungarian import * \n",
    "from pprint import pprint \n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%run Radar_Clustering_CustomDBScan.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Path Definition__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "source_dir = Path(r\"path/to/your/dataset_folder\")\n",
    "\n",
    "image_list = []\n",
    "pcd_list = []\n",
    "calibration_list = []\n",
    "scenes = [f.path for f in os.scandir(source_dir) if f.is_dir()]\n",
    "for scene in scenes:\n",
    "    # Get the path to the 'camera_01__data' directory\n",
    "    image_dir = Path(scene) / 'camera_01' / 'camera_01__data'\n",
    "    images = sorted(list(image_dir.rglob('*.png')))\n",
    "    image_list.append(images)\n",
    "\n",
    "    pcd_dir = Path(scene) / 'radar_01' / 'radar_01__data'\n",
    "    pcds = sorted(list(pcd_dir.rglob('*.pcd')))\n",
    "    pcd_list.append(pcds)\n",
    "\n",
    "    calibration_path = Path(scene)\n",
    "    calibration_dir = list(calibration_path.rglob('calibration.json'))\n",
    "    calibration_list.extend(calibration_dir)\n",
    "\n",
    "yolo_model = YOLO('path/to/your/trained_model')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_images = Path('path/to/your/images_folder')\n",
    "path_to_pcd = Path('path/to/your/radar_pcd_folder')\n",
    "\n",
    "scene_image = sorted(list(image for image in path_to_images.iterdir()))\n",
    "scene_pcd = sorted(list(image for image in path_to_pcd.iterdir()))\n",
    "\n",
    "# scene_image = scene_image[30:31]\n",
    "# scene_pcd = scene_pcd[30:31]\n",
    "\n",
    "yolo_model = YOLO('path/to/your/trained_model')\n",
    "\n",
    "calibration_file = Path('path/to/your/calibration_file')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function to Process YOLO prediction results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_box_generator_for_pred(prediction_results):\n",
    "    for result in prediction_results:\n",
    "        cls = result.boxes.cls.cpu().numpy()\n",
    "        conf = result.boxes.conf.cpu().numpy()\n",
    "        detection = result.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        list_of_pred_boxes = np.column_stack((cls, detection, conf))\n",
    "    \n",
    "    return list_of_pred_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Calibration Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_calibration_dict(calibration_file):\n",
    "    sensor_calibration_dict = {\n",
    "        \"camera_intrinsics\": [],\n",
    "        \"camera_distcoeffs\": [],\n",
    "        \"radar_to_camera\": [],\n",
    "        \"radar_to_lidar\": [],\n",
    "        \"lidar_to_ground\": [],\n",
    "        \"camera_to_ground\": []\n",
    "    }\n",
    "\n",
    "    with open(calibration_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in data['calibration']:\n",
    "        if item['calibration'] == 'camera_01':\n",
    "            sensor_calibration_dict['camera_intrinsics'] = item['k']\n",
    "            sensor_calibration_dict['camera_distcoeffs'] = item['D']\n",
    "        elif item['calibration'] == 'radar_01_to_camera_01':\n",
    "            sensor_calibration_dict['radar_to_camera'] = item['T']\n",
    "        elif item['calibration'] == 'radar_01_to_lidar_01':\n",
    "            sensor_calibration_dict['radar_to_lidar'] = item['T']\n",
    "        elif item['calibration'] == 'lidar_01_to_ground':\n",
    "            sensor_calibration_dict['lidar_to_ground'] = item['T']\n",
    "        elif item['calibration'] == 'camera_01_to_ground_homography':\n",
    "            sensor_calibration_dict['camera_to_ground'] = item['T']\n",
    "\n",
    "    return sensor_calibration_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Radar to Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_ground_transfomer(points_array, T, K):\n",
    "\n",
    "    n_p_array = np.array(points_array).reshape(1,-1)\n",
    "    tranposed_array = np.transpose(n_p_array)\n",
    "   \n",
    "    row_of_ones = np.ones((1, 1))           #1x1\n",
    "    stacked_matrix = np.vstack((tranposed_array, row_of_ones))  \n",
    "  \n",
    "    radar_to_lidar_matrix = np.matmul(T, stacked_matrix)             #3x1\n",
    "\n",
    "    new_stacked_matrix = np.vstack((radar_to_lidar_matrix, row_of_ones))             #4x1\n",
    "    in_ground_data = np.matmul(K, new_stacked_matrix)\n",
    "\n",
    "\n",
    "    in_ground = np.transpose(in_ground_data)\n",
    "\n",
    "    return in_ground[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Radar dict: on Ground__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_ground(radar_dict, sensor_calibration_dict):\n",
    "    \n",
    "    T = sensor_calibration_dict['radar_to_lidar']\n",
    "    K = sensor_calibration_dict['lidar_to_ground']\n",
    "\n",
    "    in_radar = radar_dict\n",
    "    in_ground = {'clusters': [], 'noise': []}\n",
    "    for key, value in in_radar.items():\n",
    "        if key == 'clusters':\n",
    "            for point in value:\n",
    "                if point:\n",
    "                    updated_centroid = radar_to_ground_transfomer(point[0], T, K)\n",
    "                    updated_lowest_point = radar_to_ground_transfomer(point[1], T, K)\n",
    "                    updated_velocity = point[2]\n",
    "                    updated_point = [list(updated_centroid), list(updated_lowest_point), list(updated_velocity)]\n",
    "\n",
    "                    if key in in_ground:\n",
    "                        in_ground[key].append(updated_point)\n",
    "                    else:\n",
    "                        print('no key exist')\n",
    "        else:\n",
    "            for point in value:\n",
    "                if point:\n",
    "                    updated_centroid = radar_to_ground_transfomer(point[0], T, K)\n",
    "                    updated_velocity = point[1]\n",
    "                    updated_point = [list(updated_centroid), list(updated_velocity)]\n",
    "\n",
    "                    if key in in_ground:\n",
    "                        in_ground[key].append(updated_point)\n",
    "                    else:\n",
    "                        print('no key exist')\n",
    "                    \n",
    "    return in_ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Radar to Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_camera_transformer(radar_point, T, k):\n",
    "   \n",
    "    n_p_array = np.array(radar_point).reshape(1,-1)\n",
    "    transpose_RPA = np.transpose(n_p_array)\n",
    "\n",
    "    new_array = np.vstack([transpose_RPA, np.ones((1, 1))])             \n",
    "    product_1 = np.matmul(np.array(k), np.array(T))\n",
    "\n",
    "    product_array = np.matmul(product_1, new_array)                      #[su, sv, s] but along column\n",
    "\n",
    "    final_array = product_array / product_array [2]                      #[u, v, 1], along column\n",
    "\n",
    "    u_v = np.delete(final_array, 2, axis = 0)                            #[u, v], along column      \n",
    "    final_u_v = np.transpose(u_v)\n",
    "\n",
    "    return final_u_v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Radar Dict: on Image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_to_camera(radar_output, sensor_calibration_dict):\n",
    "    T =  sensor_calibration_dict['radar_to_camera']\n",
    "    K = sensor_calibration_dict['camera_intrinsics']\n",
    "    \n",
    "    in_radar = radar_output\n",
    "    in_camera = {'clusters': [], 'noise': []}\n",
    "    for key, value in in_radar.items():\n",
    "        if key == 'clusters':\n",
    "            for point in value:\n",
    "                if point:\n",
    "                    updated_centroid = radar_to_camera_transformer(point[0], T, K)\n",
    "                    updated_lowest_point = radar_to_camera_transformer(point[1], T, K)\n",
    "                    updated_velocity = point[2]\n",
    "                    updated_point = [list(updated_centroid), list(updated_lowest_point), list(updated_velocity)]\n",
    "\n",
    "                    if key in in_camera:\n",
    "                        in_camera[key].append(updated_point)\n",
    "                    else:\n",
    "                        print('no key exist')\n",
    "\n",
    "        if key == 'noise':\n",
    "            for point in value:\n",
    "                if point:\n",
    "                    updated_centroid = radar_to_camera_transformer(point[0], T, K)\n",
    "                    updated_velocity = point[1]\n",
    "                    updated_point = [list(updated_centroid), list(updated_velocity)]\n",
    "\n",
    "                    if key in in_camera:\n",
    "                        in_camera[key].append(updated_point)\n",
    "                    else:\n",
    "                        print('no key exist')\n",
    "\n",
    "    return in_camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Homography: Image to Ground__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def homography2(list_of_pred_boxes):\n",
    "    ground_coordinate_list = []\n",
    "    for result in list_of_pred_boxes:\n",
    "        bbox = list(result[1:5])\n",
    "    \n",
    "        # x1y1 = np.array(bbox[:2]).reshape(1, -1)\n",
    "        # x2y2 = np.array(bbox[2:]).reshape(1, -1)\n",
    "        bottom_center_point = np.array(list(((bbox[2] + bbox[0]) / 2, bbox[3]))).reshape(1, -1) \n",
    "\n",
    "        # image_coordinates = np.concatenate((x1y1,x2y2,bottom_center_point), axis=0)\n",
    "        # image_coordinates = np.concatenate((bottom_center_point), axis=0)\n",
    "        transpose_matrix = np.vstack((np.transpose(bottom_center_point),np.ones((1,1))))\n",
    "        \n",
    "        homogeneous_coordinates = np.matmul(sensor_calibration_dict['camera_to_ground'], transpose_matrix)\n",
    "        ground_coordinates = homogeneous_coordinates / homogeneous_coordinates[-1].reshape(1, -1)\n",
    "\n",
    "        transpose_ground_coordinates = ground_coordinates.T\n",
    "        g_x1y1 = transpose_ground_coordinates[0][:2]\n",
    "        # g_x2y2 = transpose_ground_coordinates[1][:2]\n",
    "        # g_xcyc = transpose_ground_coordinates[2][:2]\n",
    "\n",
    "        # ground_coordinate_list.append([list(g_x1y1), list(g_x2y2), list(g_xcyc)])\n",
    "        ground_coordinate_list.append([list(g_x1y1)])\n",
    "\n",
    "    # print(ground_coordinate_list)\n",
    "    return ground_coordinate_list\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography(points_on_image, sensor_calibration_dict):\n",
    "\n",
    "    points = np.array(points_on_image).reshape(1, -1)\n",
    "\n",
    "    transpose_matrix = np.vstack((np.transpose(points),np.ones((1,1))))\n",
    "    \n",
    "    homogeneous_coordinates = np.matmul(sensor_calibration_dict['camera_to_ground'], transpose_matrix)\n",
    "    ground_coordinates = homogeneous_coordinates / homogeneous_coordinates[-1].reshape(1, -1)\n",
    "\n",
    "    transpose_ground_coordinates = ground_coordinates.T\n",
    "    g_x1y1 = transpose_ground_coordinates[0][:2]\n",
    "\n",
    "    return g_x1y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization: Camera Points on Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_plotting(image_on_ground, my_plot):\n",
    "        x_plotting_list = []\n",
    "        y_plotting_list = []\n",
    "\n",
    "        for xy in image_on_ground:\n",
    "                x_coords = [xy[1][0]]\n",
    "                y_coords = [xy[1][1]]\n",
    "\n",
    "                x_plotting_list.append(x_coords)\n",
    "                y_plotting_list.append(y_coords)\n",
    "        \n",
    "        colors = ['blue', 'green', 'orange', 'black', 'purple', 'maroon']\n",
    "\n",
    "        for i, (x_co, y_co) in enumerate(zip(x_plotting_list, y_plotting_list)):\n",
    "                my_plot.scatter(y_co, x_co, color=colors[i], label= 'camera', marker='o')\n",
    "\n",
    "        my_plot.set_xlim(-30,30)\n",
    "        my_plot.set_ylim(0,100)\n",
    "        my_plot.set_xlabel('Y-axis')\n",
    "        my_plot.set_ylabel('X-axis')\n",
    "        my_plot.set_title('Plot of Points')\n",
    "        my_plot.invert_xaxis()\n",
    "        \n",
    "        return my_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualization: Radar points on Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_plotting(dict, my_plot):\n",
    "    clusters = dict['clusters']\n",
    "    noise_points = dict['noise']\n",
    "\n",
    "    x_lowest = []\n",
    "    y_lowest = []\n",
    "\n",
    "    x_noise = []\n",
    "    y_noise = []\n",
    "\n",
    "    for detection in clusters:\n",
    "        if len(detection) != 0:\n",
    "            lowest_point = detection[1]\n",
    "            x_lp = lowest_point[0]\n",
    "            y_lp = lowest_point[1]\n",
    "            x_lowest.append(x_lp)\n",
    "            y_lowest.append(y_lp)\n",
    "    \n",
    "    for noise in noise_points:\n",
    "        if len(noise) != 0:\n",
    "            lowest_point = noise[0]\n",
    "            x_n = lowest_point[0]\n",
    "            y_n = lowest_point[1]\n",
    "            x_noise.append(x_n)\n",
    "            y_noise.append(y_n)\n",
    "\n",
    "\n",
    "    my_plot.scatter(y_lowest, x_lowest, color='red', label='lowest point', marker=\"X\")\n",
    "    my_plot.scatter(y_noise, x_noise, color='grey', label='Noise', marker=\".\")\n",
    "\n",
    "    if not my_plot.get_legend():\n",
    "        my_plot.legend()\n",
    "\n",
    "    return my_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expand Bounding Box Dimension__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_bbox(box, scale=1.1):\n",
    "    # Calculate the width and height of the original box\n",
    "    width = box[2] - box[0]     # x2 - x1\n",
    "    height = box[3] - box[1]    # y2 - y1\n",
    "\n",
    "    # Calculate the center of the original box\n",
    "    center_x = box[0] + (width/2)\n",
    "    center_y = box[1] + (height/2)\n",
    "\n",
    "    # Calculate the increase in width and height\n",
    "    new_width = width * scale\n",
    "    new_height = height * scale\n",
    "\n",
    "    # Calculate the new coordinates\n",
    "    new_x1 = 0 if (center_x - new_width / 2) < 0 else (center_x - new_width / 2)\n",
    "    new_y1 = 0 if (center_y - new_height / 2) < 0 else (center_y - new_height / 2)\n",
    "    new_x2 = center_x + new_width / 2\n",
    "    new_y2 = center_y + new_height / 2\n",
    "    \n",
    "    return list([new_x1, new_y1, new_x2, new_y2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Euclidean Distance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(clusters, images):\n",
    "    d = np.sqrt(((clusters[0] - images[0])**2) + ((clusters[1] - images[1])**2))\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Case Filtering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_association_matrix(list_of_pred_boxes, cluster_on_image, datatype='clusters', association_list=None):\n",
    "\n",
    "    clusters = list(cluster_on_image['clusters']) if datatype == 'clusters' else list(cluster_on_image['noise'])\n",
    "    pred_boxes = list(list_of_pred_boxes)\n",
    "\n",
    "    if len(clusters) > 0 and len(pred_boxes) > 0:\n",
    "        matrix = np.zeros((len(clusters), len(pred_boxes)))\n",
    "\n",
    "        for pred_idx, prediction in enumerate(pred_boxes):\n",
    "            old_bbox = prediction[1:5]  \n",
    "            bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "            for cluster_idx, cluster in enumerate(clusters):\n",
    "                cluster_centroid = cluster[0]\n",
    "                \n",
    "                if datatype == 'clusters':  \n",
    "                    if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                        matrix[cluster_idx, pred_idx] = 1\n",
    "                    else: \n",
    "                        matrix[cluster_idx, pred_idx] = 0\n",
    "\n",
    "                elif datatype == 'noise':\n",
    "                    if pred_idx in association_list['non_associated_bbox']:\n",
    "                        if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                            matrix[cluster_idx, pred_idx] = 1\n",
    "                        else: \n",
    "                            matrix[cluster_idx, pred_idx] = 0\n",
    "\n",
    "        return matrix \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_association_matrix(list_of_pred_boxes, cluster_on_image, datatype='clusters', association_list=None):\n",
    "\n",
    "    if datatype == 'clusters':\n",
    "        clusters = list(cluster_on_image['clusters']) \n",
    "        pred_boxes = list(list_of_pred_boxes)\n",
    "\n",
    "        if len(clusters) > 0 and len(pred_boxes)>0:\n",
    "            matrix = np.zeros((len(clusters), len(pred_boxes))) \n",
    "            for pred_idx, prediction in enumerate(pred_boxes):\n",
    "                \n",
    "                old_bbox = prediction[1:5]  \n",
    "                bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "                for cluster_idx, cluster in enumerate(clusters):\n",
    "                    cluster_centroid = cluster[0]\n",
    "                    \n",
    "                    if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                        matrix[cluster_idx, pred_idx] = 1\n",
    "\n",
    "                    else: \n",
    "                        matrix[cluster_idx, pred_idx] = 0\n",
    "\n",
    "            return matrix \n",
    "\n",
    "\n",
    "    elif datatype == 'noise':\n",
    "        clusters = list(cluster_on_image['noise'])\n",
    "        pred_boxes = list(list_of_pred_boxes)\n",
    "        # pred_boxes = [list(box) for idx, box in enumerate(list_of_pred_boxes) if idx in association_list['non_associated_bbox']]\n",
    "\n",
    "        if len(clusters) > 0 and len(pred_boxes)>0:\n",
    "            matrix = np.zeros((len(clusters), len(pred_boxes))) \n",
    "            for pred_idx, prediction in enumerate(pred_boxes):\n",
    "                \n",
    "                old_bbox = prediction[1:5]  \n",
    "                bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "                for cluster_idx, cluster in enumerate(clusters):\n",
    "                    cluster_centroid = cluster[0]\n",
    "\n",
    "                    if pred_idx  not in association_list['non_associated_bbox']:\n",
    "                        if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                            matrix[cluster_idx, pred_idx] = 1\n",
    "\n",
    "                    else: \n",
    "                        matrix[cluster_idx, pred_idx] = 0\n",
    "\n",
    "\n",
    "        return matrix \n",
    "\n",
    "    \n",
    "    else:\n",
    "        print('KeyError')\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_association_matrix(list_of_pred_boxes, cluster_on_image):\n",
    "\n",
    "    clusters = list(cluster_on_image['clusters'])\n",
    "    # noise_points = list(cluster_on_image['noise'])\n",
    "    pred_boxes = list(list_of_pred_boxes)\n",
    "\n",
    "    if len(clusters) > 0 and len(pred_boxes)>0:\n",
    "        matrix = np.zeros((len(clusters), len(pred_boxes))) \n",
    "        for pred_idx, prediction in enumerate(pred_boxes):\n",
    "            \n",
    "            old_bbox = prediction[1:5]  \n",
    "            bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "            for cluster_idx, cluster in enumerate(clusters):\n",
    "                cluster_centroid = cluster[0]\n",
    "                \n",
    "                if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                    matrix[cluster_idx, pred_idx] = 1\n",
    "\n",
    "                else: \n",
    "                    matrix[cluster_idx, pred_idx] = 0\n",
    "\n",
    "        return matrix \n",
    "'''      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_noise_association_matrix(association_list, list_of_pred_boxes, cluster_on_image):\n",
    "\n",
    "    # clusters = list(cluster_on_image['clusters'])\n",
    "    noise_points = list(cluster_on_image['noise'])\n",
    "\n",
    "    if not association_list['non_associated_bbox']:\n",
    "        pred_boxes = list(list_of_pred_boxes)\n",
    "    else:\n",
    "        pred_boxes = [list(box) for idx, box in enumerate(list_of_pred_boxes) if idx in association_list['non_associated_bbox']]\n",
    "\n",
    "    pprint(pred_boxes)\n",
    "\n",
    "\n",
    "    if len(noise_points) > 0 and len(pred_boxes)>0:\n",
    "        matrix = np.zeros((len(noise_points), len(pred_boxes))) \n",
    "        for pred_idx, prediction in enumerate(pred_boxes):\n",
    "            \n",
    "            old_bbox = prediction[1:5]  \n",
    "            bbox = expand_bbox(old_bbox, scale=1.2)\n",
    "\n",
    "            for noise_idx, noise in enumerate(noise_points):\n",
    "                noise_centroid = noise[0]\n",
    "                \n",
    "                if bbox[0] < noise_centroid[0] < bbox[2] and bbox[1] < noise_centroid[1] < bbox[3]:\n",
    "                    matrix[noise_idx, pred_idx] = 1\n",
    "\n",
    "                else: \n",
    "                    matrix[noise_idx, pred_idx] = 0\n",
    "\n",
    "        return matrix \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_cases(matrix, datatype='clusters', association_list=None):\n",
    "    \"\"\"\n",
    "    Checks and assigns different cases of radar-image data for spatial association \n",
    "\n",
    "    Examples: \n",
    "    >>> import pprint\n",
    "    >>> matrix = np.array([\n",
    "    ...     [1, 0, 1, 0, 0, 0],\n",
    "    ...     [0, 1, 1, 0, 0, 0],\n",
    "    ...     [1, 1, 0, 0, 0, 0],\n",
    "    ...     [0, 0, 0, 1, 0, 0],\n",
    "    ...     [0, 0, 0, 0, 1, 0],\n",
    "    ...     [0, 0, 0, 0, 1, 0],\n",
    "    ...     [0, 0, 0, 0, 0, 0]\n",
    "    ... ])\n",
    "    >>> pprint.pprint(get_associations(matrix))\n",
    "    {'many_radar_to_many_image': {'cols': [0, 1, 2], 'rows': [0, 1, 2]},\n",
    "     'many_radar_to_one_image': {'cols': [4], 'rows': [(array([4, 5]),)]},\n",
    "     'one_radar_to_many_image': {'cols': [], 'rows': []},\n",
    "     'one_radar_to_one_image': {'cols': [3], 'rows': [3]}}\n",
    "    \"\"\" \n",
    "    associations = {\n",
    "        \"many_cluster_to_many_bbox\" : {\"clusters\": [], \"bbox\": []}, \n",
    "        \"many_cluster_to_one_bbox\"  : {\"clusters\": [], \"bbox\": []},\n",
    "        \"one_cluster_to_many_bbox\"  : {\"clusters\": [], \"bbox\": []}, \n",
    "        \"one_cluster_to_one_bbox\"   : {\"assigned\": []},\n",
    "        \"unassigned_bbox\" : {\"bbox\": []}\n",
    "    }\n",
    "\n",
    "    # MANY TO MANY CHECKS\n",
    "    # -------------------\n",
    "    rows_with_multiple_truths = np.where(np.sum(matrix, axis=1) > 1)[0] \n",
    "    columns_with_multiple_truths = np.where(np.sum(matrix, axis=0) > 1)[0] \n",
    "    # many_too_many = list(set(rows_with_multiple_truths) & set(columns_with_multiple_truths))\n",
    "    # many_radar_to_many_image = [many_too_many, many_too_many]\n",
    "    many_too_many_rows = set() \n",
    "    many_too_many_cols = set() \n",
    "    for r_id in range(matrix.shape[0]):\n",
    "        for c_id in range(matrix.shape[1]):\n",
    "            if r_id in rows_with_multiple_truths and c_id in columns_with_multiple_truths: \n",
    "                if matrix[r_id, c_id] == 1:\n",
    "                     many_too_many_rows.add(r_id)\n",
    "                     many_too_many_cols.add(c_id)\n",
    "\n",
    "    associations['many_cluster_to_many_bbox'][\"clusters\"] = list(many_too_many_rows)\n",
    "    associations['many_cluster_to_many_bbox'][\"bbox\"] = list(many_too_many_cols)\n",
    "\n",
    "    # MANY TO ONE CHECKS \n",
    "    # -------------------\n",
    "    many_to_one = [] \n",
    "    for c in range(matrix.shape[1]): \n",
    "        if c in columns_with_multiple_truths and c not in many_too_many_cols:\n",
    "            associated_rows = np.where(matrix[:, c] > 0)[0]\n",
    "            associations['many_cluster_to_one_bbox'][\"clusters\"].append(associated_rows.tolist())\n",
    "            associations['many_cluster_to_one_bbox'][\"bbox\"].append([c])            \n",
    "\n",
    "    # ONE TO MANY CHECKS\n",
    "    # ------------------\n",
    "    one_to_many = [] \n",
    "    for r in range(matrix.shape[0]): \n",
    "        if r in rows_with_multiple_truths and r not in many_too_many_rows:\n",
    "            associated_cols = np.where(matrix[r] > 0)[0]\n",
    "            associations['one_cluster_to_many_bbox'][\"clusters\"].append([r])\n",
    "            associations['one_cluster_to_many_bbox'][\"bbox\"].append(associated_cols.tolist())\n",
    "\n",
    "    # ONE TO ONE CHECKS\n",
    "    # ------------------\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[0])):\n",
    "            if matrix[i,j] == 1:\n",
    "                row_sum = sum(matrix[i,:])\n",
    "                col_sum = sum(matrix[:,j]) \n",
    "\n",
    "                if row_sum == 1 and col_sum == 1:\n",
    "                    associations['one_cluster_to_one_bbox']['assigned'].append([i, j]) \n",
    "\n",
    "    if datatype == 'clusters':\n",
    "        associations[\"unassigned_bbox\"][\"bbox\"].extend(list(np.where(np.sum(matrix, axis=0) == 0)[0]))\n",
    "    elif datatype == 'noise':\n",
    "        associations[\"unassigned_bbox\"][\"bbox\"].extend(box for box in list(np.where(np.sum(matrix, axis=0) == 0)[0]) if box in association_list['non_associated_bbox']) \n",
    "\n",
    "    return associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: One to One @Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_to_one_association(filtered_cases, association_list):\n",
    "    association_list[\"associated\"].extend(filtered_cases['one_cluster_to_one_bbox']['assigned']) \n",
    "    association_list[\"non_associated_bbox\"].extend(filtered_cases[\"unassigned_bbox\"][\"bbox\"]) \n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_one_one_association(list_of_pred_boxes, cluster_on_image):\n",
    "    \n",
    "    clusters = list(cluster_on_image['clusters'])\n",
    "    noise_points = list(cluster_on_image['noise'])\n",
    "    pred_boxes = list(list_of_pred_boxes)\n",
    "\n",
    "    association = {'associated': [], 'non_associated':{'YOLO':[], 'Radar':[]}}\n",
    "\n",
    "    if len(clusters) > 0 and len(pred_boxes)>0:\n",
    "        matrix = np.zeros((len(clusters), len(pred_boxes))) \n",
    "        for pred_idx, prediction in enumerate(pred_boxes):\n",
    "            bbox = prediction[1:5]  \n",
    "            for cluster_idx, cluster in enumerate(clusters):\n",
    "                cluster_centroid = cluster[0]\n",
    "                \n",
    "                if bbox[0] < cluster_centroid[0] < bbox[2] and bbox[1] < cluster_centroid[1] < bbox[3]:\n",
    "                    matrix[cluster_idx, pred_idx] = 1\n",
    "\n",
    "                else: \n",
    "                    matrix[cluster_idx, pred_idx] = 0\n",
    "        \n",
    "        pprint(matrix)\n",
    "\n",
    "        special_points = []\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[0])):\n",
    "                if matrix[i,j] == 1:\n",
    "                    row_sum = sum(matrix[i,:])\n",
    "                    col_sum = sum(matrix[:,j]) \n",
    "\n",
    "                    if row_sum == 1 and col_sum == 1:\n",
    "                        special_points.append((i, j))\n",
    "            \n",
    "        pprint(special_points)\n",
    "\n",
    "        for item in special_points:\n",
    "            association['associated'].append([pred_boxes[item[1]],clusters[item[0]]])\n",
    "\n",
    "        for i in range(matrix.shape[0]):\n",
    "            if not any(i == item[0] for item in special_points):\n",
    "                association[\"non_associated\"][\"Radar\"].append(clusters[i])\n",
    "            \n",
    "        for j in range(matrix.shape[1]):\n",
    "            if not any(j == item[1] for item in special_points):\n",
    "                association[\"non_associated\"][\"YOLO\"].append(pred_boxes[j])\n",
    "            \n",
    "                    \n",
    "    return association\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: One to Many @Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_to_many_association(filtered_cases, clusters_on_ground, image_on_ground, datatype='clusters', association_list=None):\n",
    "\n",
    "    if datatype == 'clusters':\n",
    "        lower_idx = 1\n",
    "    elif datatype == 'noise':\n",
    "        lower_idx = 0\n",
    "    else:\n",
    "        print('KeyError')\n",
    "\n",
    "    list_of_centroid_indices = filtered_cases['one_cluster_to_many_bbox']['clusters']\n",
    "    list_of_box_indices = filtered_cases['one_cluster_to_many_bbox']['bbox']\n",
    "\n",
    "    for centroid, bboxes in zip(list_of_centroid_indices, list_of_box_indices):\n",
    "        centroid = centroid[0]\n",
    "\n",
    "        euclidean_distances = []\n",
    "        for box in bboxes:\n",
    "            ec_distance = get_euclidean_distance(clusters_on_ground[datatype][centroid][lower_idx], image_on_ground[box][1])\n",
    "            euclidean_distances.append(ec_distance)\n",
    "        \n",
    "        min_bbox_idx = [idx for idx, value in enumerate(euclidean_distances) if value == min(euclidean_distances)]\n",
    "        min_bbox_idx = min_bbox_idx[0]\n",
    "\n",
    "        association_list['associated'].append([centroid, bboxes[min_bbox_idx]])\n",
    "        association_list['non_associated_bbox'].extend([bbox for bbox in bboxes if bbox != bboxes[min_bbox_idx]])\n",
    "\n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association: Many to One__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_point_finder(points_list, processed_radar_points_to_ground):\n",
    "    x_list = []\n",
    "    for point in points_list:\n",
    "        x_p = processed_radar_points_to_ground['clusters'][point][1][0]\n",
    "        x_list.append(x_p)\n",
    "    \n",
    "    return x_list.index(min(x_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_many_to_one_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters'):\n",
    "\n",
    "    clusters = filtered_cases['many_cluster_to_one_bbox']['clusters']\n",
    "    pre_boxes = filtered_cases['many_cluster_to_one_bbox']['bbox']\n",
    "\n",
    "  \n",
    "    for cluster, box in zip(clusters, pre_boxes):\n",
    "    # if count_in_clusters == 1 and count_in_boxes == 1:\n",
    "        box_data = box[0]\n",
    "        clusters_data = cluster\n",
    "        count = len(clusters_data)\n",
    "        matrix = np.zeros((count, count))\n",
    "\n",
    "        for index_p1, point_1 in enumerate(clusters_data):\n",
    "            for index_p2, point_2 in enumerate(clusters_data):\n",
    "                point_1_data = clusters_on_ground['clusters'][point_1] if datatype == 'clusters' else clusters_on_ground['noise'][point_1]\n",
    "                point_2_data = clusters_on_ground['clusters'][point_2] if datatype == 'clusters' else clusters_on_ground['noise'][point_2]\n",
    "\n",
    "                velocity_p1 = point_1_data[2][0] if datatype == 'clusters' else point_1_data[1][0]\n",
    "                velocity_p2 = point_2_data[2][0] if datatype == 'clusters' else point_2_data[1][0]\n",
    "\n",
    "                x_p1 = point_1_data[0][0]\n",
    "                x_p2 = point_2_data[0][0]\n",
    "                \n",
    "                if abs(velocity_p1 - velocity_p2) < 0.75 and abs(x_p1 - x_p2) < 2:\n",
    "                    matrix[index_p1][index_p2] = 1\n",
    "\n",
    "        candidates = []\n",
    "        for row in matrix:\n",
    "            columns_with_ones = []\n",
    "            for col_index, value in enumerate(row):\n",
    "                if value == 1:\n",
    "                    columns_with_ones.append(col_index)\n",
    "        \n",
    "            candidates.append(columns_with_ones)\n",
    "\n",
    "        new_candidates = candidates\n",
    "        global_merged_any = False\n",
    "        while True:\n",
    "            #print(new_candidates)\n",
    "            check_list = new_candidates\n",
    "            for i in range(len(new_candidates)):\n",
    "                local_merged_any = False\n",
    "                set1 = set(new_candidates[i])\n",
    "                for j in range(i + 1, len(new_candidates)):\n",
    "                    set2 = set(new_candidates[j])\n",
    "\n",
    "                    if set1 & set2:  # Check if there's any common element\n",
    "                        new_element = list(set1 | set2)\n",
    "                        remaining_points = [point for point in new_candidates if point not in [new_candidates[i], new_candidates[j]]]\n",
    "                        new_candidates = remaining_points\n",
    "                        new_candidates.insert(0, new_element) # New candidate is not emptying --no break condition \n",
    "\n",
    "                        local_merged_any = True \n",
    "                        global_merged_any = True\n",
    "                        break\n",
    "                if local_merged_any:\n",
    "                    break\n",
    "\n",
    "            # Exit condition for the while loop\n",
    "            if len(new_candidates) == len(check_list):\n",
    "                break\n",
    "                    \n",
    "        if not global_merged_any:  # If no merges occurred in this iteration, terminate the loop\n",
    "            distance_data = []\n",
    "            for idx, centroid in enumerate(clusters_data):\n",
    "                nearest_data = clusters_on_ground['clusters'][centroid][1] if datatype == 'clusters' else clusters_on_ground['noise'][centroid][0]\n",
    "                box_bottom_center = image_on_ground[box_data][1]\n",
    "                ec_distance = get_euclidean_distance(nearest_data[0:2], box_bottom_center)\n",
    "                distance_data.append(ec_distance)\n",
    "            \n",
    "            index_to_look_for_in_clusters_data = distance_data.index(min(distance_data))\n",
    "            index_of_chosen_centroid = clusters_data[index_to_look_for_in_clusters_data]\n",
    "\n",
    "            if [index_of_chosen_centroid, box_data] not in association_list['associated']:\n",
    "                association_list['associated'].append([index_of_chosen_centroid, box_data])\n",
    "            print('not merged case')\n",
    "\n",
    "        new_updated_candidate = []\n",
    "        for box_list in new_candidates:\n",
    "            updated = []\n",
    "            for box in box_list:\n",
    "                updated.append(clusters_data[box]) \n",
    "            new_updated_candidate.append(updated)\n",
    "            \n",
    "        if len(new_updated_candidate) > 1 and global_merged_any:\n",
    "\n",
    "            #This section removes the items which are not clustered\n",
    "            for pair in new_updated_candidate[:]:\n",
    "                if len(pair) < 2:\n",
    "                    new_updated_candidate.remove(pair)    \n",
    "\n",
    "            distance_comparison = []\n",
    "            for item in new_updated_candidate:\n",
    "                nearest_point = nearest_point_finder(item, clusters_on_ground)\n",
    "                nearest_point_data = clusters_on_ground['clusters'][item[nearest_point]][1] if datatype == 'clusters' else clusters_on_ground['noise'][item[nearest_point]][0]\n",
    "                box_bottom_center = image_on_ground[box_data][1]\n",
    "                e_c_distance = get_euclidean_distance(nearest_point_data[0:2], box_bottom_center)\n",
    "                distance_comparison.append(e_c_distance)\n",
    "\n",
    "            final_cluster_to_associate= distance_comparison.index(min(distance_comparison))\n",
    "            index_of_chosen_centroid = new_updated_candidate[final_cluster_to_associate]\n",
    "\n",
    "            #print(final_candidate, box_data)\n",
    "            association_list['associated'].append([index_of_chosen_centroid, box_data])\n",
    "\n",
    "        elif len(new_updated_candidate) == 1:\n",
    "            association_list['associated'].append([new_updated_candidate[0], box_data])\n",
    "        \n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Many to Many__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_many_to_many_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters'):\n",
    "\n",
    "    clusters = filtered_cases['many_cluster_to_one_bbox']['clusters']\n",
    "    pre_boxes = filtered_cases['many_cluster_to_one_bbox']['bbox']\n",
    "\n",
    "    \n",
    "    first_matrix = np.zeros((len(clusters), len(clusters)))\n",
    "\n",
    "    for index_p1, point_1 in enumerate(clusters):\n",
    "            for index_p2, point_2 in enumerate(clusters):\n",
    "                point_1_data = clusters_on_ground['clusters'][point_1] if datatype == 'clusters' else clusters_on_ground['noise'][point_1]\n",
    "                point_2_data = clusters_on_ground['clusters'][point_2] if datatype == 'clusters' else clusters_on_ground['noise'][point_2]\n",
    "\n",
    "                velocity_p1 = point_1_data[2][0] if datatype == 'clusters' else point_1_data[1][0]\n",
    "                velocity_p2 = point_2_data[2][0] if datatype == 'clusters' else point_2_data[1][0]\n",
    "                \n",
    "                if abs(velocity_p1 - velocity_p2) < 0.75:\n",
    "                    first_matrix[index_p1][index_p2] = 1\n",
    "    \n",
    "    # print(first_matrix)\n",
    "\n",
    "    candidates = []\n",
    "    for row in first_matrix:\n",
    "        columns_with_ones = []\n",
    "        for col_index, value in enumerate(row):\n",
    "            if value == 1:\n",
    "                columns_with_ones.append(col_index)\n",
    "    \n",
    "        candidates.append(columns_with_ones)\n",
    "\n",
    "    #########################################################################################################################\n",
    "    new_candidates = candidates\n",
    "    global_merged_any = False\n",
    "    while True:\n",
    "        #print(new_candidates)\n",
    "        check_list = new_candidates\n",
    "        for i in range(len(new_candidates)):\n",
    "            local_merged_any = False\n",
    "            set1 = set(new_candidates[i])\n",
    "            for j in range(i + 1, len(new_candidates)):\n",
    "                set2 = set(new_candidates[j])\n",
    "\n",
    "                if set1 & set2:  # Check if there's any common element\n",
    "                    new_element = list(set1 | set2)\n",
    "                    remaining_points = [point for point in new_candidates if point not in [new_candidates[i], new_candidates[j]]]\n",
    "                    new_candidates = remaining_points\n",
    "                    new_candidates.insert(0, new_element) # New candidate is not emptying --no break condition \n",
    "\n",
    "                    local_merged_any = True \n",
    "                    global_merged_any = True\n",
    "                    break\n",
    "            if local_merged_any:\n",
    "                break\n",
    "\n",
    "        # Exit condition for the while loop\n",
    "        if len(new_candidates) == len(check_list):\n",
    "            break\n",
    "\n",
    "    ################################################################################################################\n",
    "    if not global_merged_any:  # If no merges occurred in this iteration, terminate the loop\n",
    "\n",
    "        second_matrix = np.zeros((len(clusters), len(pre_boxes)))\n",
    "\n",
    "        for cluster in clusters:\n",
    "            for box in pre_boxes:\n",
    "                cluster_nearest_point_data = clusters_on_ground['clusters'][cluster][1]  if datatype == 'clusters' else clusters_on_ground['noise'][cluster][0]\n",
    "                box_bottom_center_data = image_on_ground[box][1]\n",
    "                e_c_distance = get_euclidean_distance(cluster_nearest_point_data[0:2], box_bottom_center_data)\n",
    "                second_matrix[cluster][box] = e_c_distance\n",
    "        \n",
    "        n_rows, n_cols = second_matrix.shape\n",
    "        combined_indices = []\n",
    "\n",
    "        for col_idx in range(n_cols):\n",
    "            # Get the column and apply the threshold condition\n",
    "            column = second_matrix.shape[:, col_idx]\n",
    "            valid_indices = np.where(column < 2)[0]\n",
    "            \n",
    "            if valid_indices.size > 0:\n",
    "                # Find the index of the minimum value among valid indices\n",
    "                min_value_index = valid_indices[np.argmin(column[valid_indices])]\n",
    "                combined_indices.append((min_value_index, col_idx))\n",
    "        \n",
    "        # print(combined_indices)             #list of associations where first element is cluster index and second is box index \n",
    "        for item in combined_indices:\n",
    "            new_item = clusters[item[0]], pre_boxes[item[1]]\n",
    "        association_list['associated'].extend(new_item)\n",
    "\n",
    "    #####################################################################################################################\n",
    "\n",
    "    #getting the actual indexes\n",
    "    new_updated_candidate = []\n",
    "    for box_list in new_candidates:\n",
    "        updated = []\n",
    "        for box in box_list:\n",
    "            updated.append(clusters[box]) \n",
    "        new_updated_candidate.append(updated)\n",
    "\n",
    "    if global_merged_any:\n",
    "        number_of_rows = len(new_candidates)\n",
    "        len_of_columns = len(pre_boxes)\n",
    "\n",
    "        third_matrix = np.zeros((number_of_rows, len_of_columns))\n",
    "\n",
    "        for merged in new_candidates:\n",
    "            for box in pre_boxes:\n",
    "                if len(merged) > 1:\n",
    "                    nearest_point_index_in_merged = nearest_point_finder(merged, image_on_ground)\n",
    "                    nearest_point = merged[nearest_point_index_in_merged]\n",
    "                else:\n",
    "                    nearest_point = merged[0]\n",
    "                \n",
    "                nearest_point_data = clusters_on_ground['cluster'][nearest_point][1] if datatype == 'clusters' else clusters_on_ground['noise'][nearest_point][0]\n",
    "                box_bottom_center = image_on_ground[box][1]\n",
    "                e_c_distance = get_euclidean_distance(nearest_point_data[0:2], box_bottom_center)\n",
    "                third_matrix[merged][box] = e_c_distance\n",
    "        \n",
    "\n",
    "        n_rows, n_cols = third_matrix.shape\n",
    "        combined_indices = []\n",
    "\n",
    "        for col_idx in range(n_cols):\n",
    "            # Get the column and apply the threshold condition\n",
    "            column = third_matrix.shape[:, col_idx]\n",
    "            valid_indices = np.where(column < 2)[0]\n",
    "            \n",
    "            if valid_indices.size > 0:\n",
    "                # Find the index of the minimum value among valid indices\n",
    "                min_value_index = valid_indices[np.argmin(column[valid_indices])]\n",
    "                combined_indices.append((min_value_index, col_idx))\n",
    "        \n",
    "        # print(combined_indices)             #list of associations where first element is cluster index and second is box index \n",
    "\n",
    "        for item in combined_indices:\n",
    "            new_item = new_candidates[item[0]], pre_boxes[item[1]]\n",
    "        association_list['associated'].extend(new_item)\n",
    "    \n",
    "    for boxes in pre_boxes:\n",
    "        if boxes not in list(item[1] for item in association_list['associated']):\n",
    "            association_list['non_associated'].append(boxes)\n",
    "\n",
    "    return association_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jayesh__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def find_and_group_similar_velocities(radar_on_camera, velocities, threshold=0.5, datatype='clusters'):\n",
    "        grouped_points = []\n",
    "        used_indices = set()\n",
    "        if datatype == 'noise': \n",
    "            points = radar_on_camera['noise']\n",
    "            v_index = 1 # Due to different structure, the position of velocity will be different\n",
    "        else: \n",
    "            points = radar_on_camera['clusters']\n",
    "            v_index = 2\n",
    "\n",
    "        for i in velocities:\n",
    "            if i not in used_indices:\n",
    "                current_group = [i]\n",
    "                used_indices.add(i)\n",
    "                for j in velocities[i+1:]:\n",
    "                    if abs(points[i][v_index][0] - points[j][v_index][0]) <= threshold:\n",
    "                        current_group.append(j)\n",
    "                        used_indices.add(j)\n",
    "                grouped_points.append(current_group)\n",
    "        \n",
    "        return grouped_points'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def merge_clusters(clusters_on_radar, clusters, datatype='clusters'):\n",
    "        avg_centroid = np.empty((1,3))\n",
    "        avg_lowest_point = np.empty((1,3))\n",
    "        avg_velocity = 0\n",
    "        if datatype=='noise': \n",
    "            points = clusters_on_radar['noise']\n",
    "            v_index = 1\n",
    "        else: \n",
    "            points = clusters_on_radar['clusters']\n",
    "            v_index = 2\n",
    "        \n",
    "        for cluster in clusters:\n",
    "            # print(f\"Cluster: {cluster}\")\n",
    "            # print(f\"Points: {points}\")\n",
    "            avg_centroid += np.array(points[cluster][0])\n",
    "            avg_lowest_point += np.array(points[cluster][1])\n",
    "            avg_velocity += points[cluster][v_index][0] \n",
    "        \n",
    "        avg_centroid /= len(clusters)\n",
    "        avg_lowest_point /= len(clusters)\n",
    "        avg_velocity /= len(clusters)\n",
    "\n",
    "        merged_cluster = [avg_centroid.tolist()[0], avg_lowest_point.tolist()[0], [avg_velocity]]\n",
    "\n",
    "        return merged_cluster\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_many_to_many(filtered_cases, clusters_on_image, velocity_threshold=0.75, datatype='clusters')\n",
    "    if datatype == 'clusters':\n",
    "        merged_clusters_indexes = find_and_group_similar_velocities(clusters_on_image, filtered_cases['many_cluster_to_many_bbox'][\"clusters\"], threshold=0.5, datatype='clusters')\n",
    "        merged_clusters_indexes_copy = merged_clusters_indexes\n",
    "\n",
    "        merged_clusters = [merge_clusters(clusters) for clusters in merged_clusters_indexes if len(clusters)>1]\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_noise_one_to_many_association(filtered_cases, noise_association_list, clusters_on_ground, image_on_ground):\n",
    "\n",
    "    list_of_noise_indices = filtered_cases['one_cluster_to_many_bbox']['clusters']\n",
    "    list_of_box_indices = filtered_cases['one_cluster_to_many_bbox']['bbox']\n",
    "\n",
    "    for centroid, bboxes in zip(list_of_noise_indices, list_of_box_indices):\n",
    "        centroid = centroid[0]\n",
    "\n",
    "        euclidean_distances = []\n",
    "        for box in bboxes:\n",
    "            ec_distance = get_euclidean_distance(clusters_on_ground['noise'][centroid][0], image_on_ground[box][1])\n",
    "            euclidean_distances.append(ec_distance)\n",
    "        \n",
    "        min_bbox_idx = [idx for idx, value in enumerate(euclidean_distances) if value == min(euclidean_distances)]\n",
    "        min_bbox_idx = min_bbox_idx[0]\n",
    "\n",
    "        noise_association_list['associated'].append([centroid, bboxes[min_bbox_idx]])\n",
    "        noise_association_list['non_associated_bbox'].extend([bbox for bbox in bboxes if bbox != bboxes[min_bbox_idx]])\n",
    "\n",
    "    return noise_association_list\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make Association Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_association_matrix(image_points_on_ground, radar_points):\n",
    "    clusters = radar_points['clusters']\n",
    "    noise_points = radar_points['noise']\n",
    "    \n",
    "    cluster_nearest_points = []\n",
    "    noise_nearest_points = []\n",
    "\n",
    "    for detection in clusters: \n",
    "        if len(detection) != 0:\n",
    "            lowest_point = detection[1]\n",
    "            x_lp = lowest_point[0]\n",
    "            y_lp = lowest_point[1]\n",
    "            cluster_nearest_points.append([list(np.array([x_lp, y_lp]))]) \n",
    "    \n",
    "    for noise in noise_points: \n",
    "        if len(noise) != 0:\n",
    "            lowest_point = noise[0]\n",
    "            x_n = lowest_point[0]\n",
    "            y_n = lowest_point[1]\n",
    "            noise_nearest_points.append([list(np.array([x_n, y_n]))])     \n",
    "    \n",
    "\n",
    "    total_list = cluster_nearest_points + noise_nearest_points\n",
    "\n",
    "    association_matrix = np.zeros((len(total_list),len(image_points_on_ground)))\n",
    "\n",
    "    for cluster_idx, cluster_point in enumerate(total_list):\n",
    "        for img_idx, img_point in enumerate(image_points_on_ground):\n",
    "            association_matrix[cluster_idx, img_idx] = get_euclidean_distance(cluster_point[0], img_point[0])\n",
    "\n",
    "    \n",
    "    return association_matrix   \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Greedy Object Association__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def assign_objects(_matrix):\n",
    "    \n",
    "    for i_dx in range(_matrix.shape[0]):\n",
    "        _matrix[i_dx,][_matrix[i_dx,] != np.max(_matrix[i_dx,])] = 0\n",
    "\n",
    "    for i_gx in range(_matrix.shape[1]):\n",
    "        _matrix[:, i_gx][_matrix[:,i_gx] != np.max(_matrix[:,i_gx])] = 0 \n",
    "\n",
    "    return _matrix \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Update Dict: Image Plane to Ground Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def update_dict_image_ground(dictionary_after_1t1, sensor_calibration_dict):\n",
    "    _to_ground_dict = {'associated': [], 'non_associated': {'YOLO': [], 'Radar': []}}\n",
    "    \n",
    "    for result in dictionary_after_1t1['non_associated']['YOLO']:\n",
    "        cls = result[0]\n",
    "        bbox = list(result[1:5])\n",
    "        bottom_center_point = list(((bbox[2] + bbox[0]) / 2, bbox[3]))\n",
    "        image_point_on_ground = list(homography(bottom_center_point, sensor_calibration_dict))\n",
    "        _to_ground_dict['non_associated']['YOLO'].append([[cls], image_point_on_ground])\n",
    "\n",
    "\n",
    "    for cluster in dictionary_after_1t1['non_associated']['Radar']:\n",
    "        centroid = cluster[0]\n",
    "        lower = cluster[1]\n",
    "        velocity = cluster[2]\n",
    "        _centroid = list(homography(centroid,sensor_calibration_dict))\n",
    "        _lower = list(homography(lower, sensor_calibration_dict))\n",
    "        _to_ground_dict['non_associated']['Radar'].append([_centroid, _lower, velocity])\n",
    "\n",
    "\n",
    "    for item in dictionary_after_1t1['associated']:\n",
    "        cls = item[0][0]\n",
    "        bbox_lower = item[0][1]\n",
    "        radar_data = item[1]\n",
    "        centroid = radar_data[0]\n",
    "        velocity = radar_data[2]\n",
    "        _centroid = list(homography(centroid, sensor_calibration_dict))\n",
    "        _to_ground_dict['associated'].append([[cls], _centroid, velocity])\n",
    "\n",
    "    return _to_ground_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Association Visualization @Image Plane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drawings(colour_idx, image, box_data, centroid_data, datatype='clusters'):\n",
    "\n",
    "    colors = [\n",
    "        (255, 0, 0),    # Blue\n",
    "        (0, 255, 0),    # Green\n",
    "        (0, 0, 255),    # Red\n",
    "        (255, 255, 0),  # Cyan\n",
    "        (255, 0, 255),  # Magenta\n",
    "        (0, 255, 255),  # Yellow\n",
    "        (128, 0, 0),    # Maroon\n",
    "        (0, 128, 0),    # Dark Green\n",
    "        (0, 0, 128),    # Navy\n",
    "        (128, 128, 0)   # Olive\n",
    "    ]\n",
    "\n",
    "    # Calculate the Corners\n",
    "    original_box = box_data[1:5]\n",
    "    # pprint(original_box)\n",
    "    corner_1 = tuple(map(int, [original_box[0], original_box[1]]))\n",
    "    corner_2 = tuple(map(int, [original_box[2], original_box[3]]))            \n",
    "\n",
    "    # Draw Original bounding box\n",
    "    colour = colors[colour_idx]\n",
    "    thickness_of_box = 3\n",
    "    cv2.rectangle(image, corner_1, corner_2, colour, thickness_of_box)\n",
    "\n",
    "    # expand bounding boxes and calculate the corners\n",
    "    new_box = expand_bbox(box_data[1:5], scale=1.2) \n",
    "    corner_1 = tuple(map(int, [new_box[0], new_box[1]]))\n",
    "    corner_2 = tuple(map(int, [new_box[2], new_box[3]]))\n",
    "    \n",
    "\n",
    "    # Draw a Expanded bounding box with dashed Rectangle \n",
    "    img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    thickness = 3\n",
    "    dash_length = 10\n",
    "\n",
    "    for i in range(corner_1[0], corner_2[0], dash_length * 2):\n",
    "        for t in range(thickness):\n",
    "            draw.line([(i, corner_1[1]+t), (i + dash_length, corner_1[1]+t)], fill=colour[::-1])\n",
    "            draw.line([(i, corner_2[1]+t), (i + dash_length, corner_2[1]+t)], fill=colour[::-1])\n",
    "\n",
    "    for i in range(corner_1[1], corner_2[1], dash_length * 2):\n",
    "        for t in range(thickness):\n",
    "            draw.line([(corner_1[0]+t, i), (corner_1[0]+t, i + dash_length)], fill=colour[::-1])\n",
    "            draw.line([(corner_2[0]+t, i), (corner_2[0]+t, i + dash_length)], fill=colour[::-1])\n",
    "\n",
    "    image = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    \n",
    "    # Plot Centroid\n",
    "    thickness = -1  # to fill the circle\n",
    "    radius = 15\n",
    "    \n",
    "    if datatype == 'clusters':\n",
    "        cluster_point = tuple(map(int, [centroid_data[0], centroid_data[1]]))\n",
    "        image = cv2.circle(image, cluster_point, radius, colour, thickness)\n",
    "    \n",
    "    elif datatype == 'noise':     \n",
    "        cluster_point_1 = tuple(map(int, [centroid_data[0]-12, centroid_data[1]-12]))\n",
    "        cluster_point_2 = tuple(map(int, [centroid_data[0]+12, centroid_data[1]+12]))\n",
    "        image = cv2.rectangle(image, cluster_point_1, cluster_point_2, colour, thickness=3)\n",
    "    \n",
    "    elif datatype == 'unassigned':\n",
    "        pass\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img):\n",
    "\n",
    "    image = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    colour_idx = 0\n",
    "    \n",
    "\n",
    "    if final_association_dict['with_cluster']:\n",
    "        for associated_point in final_association_dict['with_cluster']:\n",
    "\n",
    "            # Get box and centroid data\n",
    "            box_data = list_of_pred_boxes[associated_point[1]]\n",
    "\n",
    "            if type(associated_point[0]) == int:\n",
    "                point = associated_point[0]\n",
    "                centroid_data = clusters_on_image['clusters'][point][0]\n",
    "                \n",
    "                # Get Annotations\n",
    "                image = get_drawings(colour_idx, image, box_data, centroid_data, datatype='clusters')\n",
    "                colour_idx += 1\n",
    "            \n",
    "            elif type(associated_point[0]) == list:\n",
    "                for point in associated_point[0]:\n",
    "                    centroid_data = clusters_on_image['clusters'][point][0]\n",
    "                    \n",
    "                    # Get Annotations\n",
    "                    image = get_drawings(colour_idx, image, box_data, centroid_data, datatype='clusters')\n",
    "                colour_idx += 1\n",
    "\n",
    "\n",
    "    if final_association_dict['with_noise']:\n",
    "        for associated_point in final_association_dict['with_noise']:\n",
    "\n",
    "            # Get box and centroid data\n",
    "            box_data = list_of_pred_boxes[associated_point[1]]\n",
    "\n",
    "            if type(associated_point[0]) == int:\n",
    "                point = associated_point[0]\n",
    "                centroid_data = clusters_on_image['noise'][point][0]\n",
    "                \n",
    "                # Get Annotations\n",
    "                image = get_drawings(colour_idx, image, box_data, centroid_data, datatype='noise')\n",
    "                colour_idx += 1\n",
    "            \n",
    "            elif type(associated_point[0]) == list:\n",
    "                for point in associated_point[0]:\n",
    "                    centroid_data = clusters_on_image['noise'][point][0]\n",
    "                    \n",
    "                    # Get Annotations\n",
    "                    image = get_drawings(colour_idx, image, box_data, centroid_data, datatype='noise')\n",
    "                colour_idx += 1\n",
    "\n",
    "\n",
    "    if final_association_dict['unassigned_bbox']:\n",
    "        for non_associated_point in final_association_dict['unassigned_bbox']:\n",
    "            # Get box and centroid data\n",
    "            box_data = list_of_pred_boxes[non_associated_point]\n",
    "            centroid_data = None\n",
    "\n",
    "            # Get Annotations\n",
    "            image = get_drawings(colour_idx, image, box_data, centroid_data, datatype='unassigned')\n",
    "            colour_idx += 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inference__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "my_image = fig.add_subplot(gs[0])\n",
    "my_plot = fig.add_subplot(gs[1])\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "# total_box = []\n",
    "# unassigned_case = []\n",
    "\n",
    "# for scene_image, scene_pcd, calibration_file in zip(image_list, pcd_list, calibration_list):\n",
    "sensor_calibration_dict = get_sensor_calibration_dict(calibration_file)\n",
    "\n",
    "for img, pcd in zip(scene_image, scene_pcd):\n",
    "    \n",
    "    # YOLO prediction\n",
    "    results = yolo_model.predict(img)\n",
    "    list_of_pred_boxes = class_box_generator_for_pred(results)\n",
    "    pprint(list_of_pred_boxes)\n",
    "    \n",
    "    # Calculate total no of boxes in all the images\n",
    "    # total_box.append(len(list_of_pred_boxes))\n",
    "    # print(total_box)\n",
    "\n",
    "    # Cluster Formation\n",
    "    db_scan = my_custom_dbscan(eps1=0.1, eps2=0.250, min_samples=2)\n",
    "    clusters_on_radar = db_scan.process_pcd_files(pcd)\n",
    "    pprint(clusters_on_radar)\n",
    "\n",
    "    # Bbox point on the Ground Plane\n",
    "    image_on_ground = []\n",
    "    for result in list_of_pred_boxes:\n",
    "        cls = result[0]\n",
    "        bbox = list(result[1:5])\n",
    "        bottom_center_point = list(((bbox[2] + bbox[0]) / 2, bbox[3]))\n",
    "        image_point_on_ground = homography(bottom_center_point, sensor_calibration_dict)\n",
    "        image_on_ground.append([[cls], list(image_point_on_ground)])\n",
    "    # pprint(image_on_ground)\n",
    "\n",
    "    # Radar Dictionaries on different Planes\n",
    "    clusters_on_ground = radar_to_ground(clusters_on_radar, sensor_calibration_dict)\n",
    "    # pprint(f\"cluster on ground: {clusters_on_ground} \")\n",
    "\n",
    "    clusters_on_image = radar_to_camera(clusters_on_radar, sensor_calibration_dict)\n",
    "    # pprint(f\"cluster on image: {clusters_on_image} \")\n",
    "\n",
    "    \n",
    "    # Fiter Cases with Association Matrix\n",
    "    association_matrix = get_association_matrix(list_of_pred_boxes, clusters_on_image, datatype= 'clusters') \n",
    "    pprint(f\" association_matrix: {association_matrix}\")\n",
    "\n",
    "    association_list = {\"associated\": [], \"non_associated_bbox\": []}\n",
    "\n",
    "    if association_matrix is not None:\n",
    "        filtered_cases = get_filtered_cases(association_matrix,  datatype='clusters')\n",
    "        # pprint(f\" filtered_cases: {filtered_cases}\")\n",
    "\n",
    "        # Association: One to One\n",
    "        association_list = get_one_to_one_association(filtered_cases, association_list)\n",
    "        # pprint(f\" after one to one: {association_list}\")\n",
    "\n",
    "        # Association: One to Many\n",
    "        association_list = get_one_to_many_association(filtered_cases, clusters_on_ground, image_on_ground, association_list=association_list, datatype= 'clusters')\n",
    "        # pprint(f\" after one to many: {association_list}\")\n",
    "\n",
    "        # Association: Many to One\n",
    "        association_list = get_many_to_one_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters')\n",
    "        # pprint(f\" after many to one: {association_list}\")\n",
    "\n",
    "        # Association: Many to Many\n",
    "        # association_list = get_many_to_many_association(filtered_cases, association_list, clusters_on_ground, image_on_ground, datatype='clusters')\n",
    "        # pprint(f\" after many to many: {association_list}\")\n",
    "\n",
    "\n",
    "        # Calculate Unassigned bbox without any clusters inside\n",
    "        # unassigned_case.append(len(association_list[\"non_associated_bbox\"][0]))\n",
    "        # print(unassigned_case)\n",
    "\n",
    "    noise_association_matrix = get_association_matrix(list_of_pred_boxes, clusters_on_image, association_list=association_list, datatype='noise')\n",
    "    pprint(f\"noise_association_matrix: {noise_association_matrix}\")\n",
    "\n",
    "    noise_association_list = {\"associated\": [], \"non_associated_bbox\": []}\n",
    "\n",
    "    if noise_association_matrix is not None:\n",
    "        noise_filtered_cases = get_filtered_cases(noise_association_matrix, datatype='noise', association_list=association_list)\n",
    "        # pprint(f\" noise filtered cases: {noise_filtered_cases}\")\n",
    "\n",
    "        # Association: One to One\n",
    "        noise_association_list = get_one_to_one_association(noise_filtered_cases, noise_association_list)\n",
    "        # pprint(f\" after one to one: {noise_association_list}\")\n",
    "\n",
    "        # Association: One to Many\n",
    "        noise_association_list = get_one_to_many_association(noise_filtered_cases, clusters_on_ground, image_on_ground, association_list=noise_association_list, datatype= 'noise')\n",
    "        # pprint(f\" after one to many: {noise_association_list}\")\n",
    "\n",
    "        # Association: Many to One    \n",
    "        noise_association_list = get_many_to_one_association(noise_filtered_cases, noise_association_list, clusters_on_ground, image_on_ground, datatype='noise')\n",
    "        # pprint(f\" after Many to One: {noise_association_list}\")\n",
    "\n",
    "\n",
    "    # Final Association List\n",
    "    final_association_dict = {'with_cluster': [], 'with_noise': [], 'unassigned_bbox': []}\n",
    "    final_association_dict['with_cluster'].extend(association_list['associated'])\n",
    "    final_association_dict['with_noise'].extend(noise_association_list['associated'])\n",
    "    final_association_dict['unassigned_bbox'].extend(noise_association_list['non_associated_bbox'])\n",
    "    \n",
    "    # pprint(final_association_dict)\n",
    "\n",
    "    \n",
    "    # Visualization:\n",
    "    my_image.clear()\n",
    "    my_plot.clear()\n",
    "\n",
    "    # Points on Ground Plane\n",
    "    plot = camera_plotting(image_on_ground, my_plot)\n",
    "    plot2 = radar_plotting(clusters_on_ground, plot)\n",
    "\n",
    "    # Association Visualization on Image Plane\n",
    "    image_visualize = get_image_visualization(final_association_dict, list_of_pred_boxes, clusters_on_image, img)\n",
    "    # cv2.imshow('on image plane', image_visualize)\n",
    "    image_visualize = cv2.cvtColor(image_visualize, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    my_image.imshow(image_visualize)\n",
    "    my_image.set_title('Image')\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    # time.sleep(100)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "# print(np.sum(total_box))\n",
    "# print(np.sum(unassigned_case))\n",
    "\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
